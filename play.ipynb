{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e54a75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Ｕｎｉｃｏｄｅ! 🅤🅝🅘🅒🅞🅓🅔‽ 🇺‌🇳‌🇮‌🇨‌🇴‌🇩‌🇪! 😄 The very name strikes fear and awe into the hearts of programmers worldwide. We all know we ought to “support Unicode” in our software (whatever that means—like using wchar_t for all the strings, right?). But Unicode can be abstruse, and diving into the thousand-page Unicode Standard plus its dozens of supplementary annexes, reports, and notes can be more than a little intimidating. I don’t blame programmers for still finding the whole thing mysterious, even 30 years after Unicode’s inception.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46fba70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'> 616 [239, 188, 181, 239, 189, 142, 239, 189, 137, 239, 189, 131, 239, 189, 143, 239, 189, 132, 239, 189, 133, 33, 32, 240, 159, 133, 164, 240, 159, 133, 157, 240, 159, 133, 152, 240, 159, 133, 146, 240, 159, 133, 158, 240, 159, 133, 147, 240, 159, 133, 148, 226, 128, 189, 32, 240, 159, 135, 186, 226, 128, 140, 240, 159, 135, 179, 226, 128, 140, 240, 159, 135, 174, 226, 128, 140, 240, 159, 135, 168, 226, 128, 140, 240, 159, 135, 180, 226, 128, 140, 240, 159, 135, 169, 226, 128, 140, 240, 159, 135, 170, 33, 32, 240, 159, 152, 132, 32, 84, 104, 101, 32, 118, 101, 114, 121, 32, 110, 97, 109, 101, 32, 115, 116, 114, 105, 107, 101, 115, 32, 102, 101, 97, 114, 32, 97, 110, 100, 32, 97, 119, 101, 32, 105, 110, 116, 111, 32, 116, 104, 101, 32, 104, 101, 97, 114, 116, 115, 32, 111, 102, 32, 112, 114, 111, 103, 114, 97, 109, 109, 101, 114, 115, 32, 119, 111, 114, 108, 100, 119, 105, 100, 101, 46, 32, 87, 101, 32, 97, 108, 108, 32, 107, 110, 111, 119, 32, 119, 101, 32, 111, 117, 103, 104, 116, 32, 116, 111, 32, 226, 128, 156, 115, 117, 112, 112, 111, 114, 116, 32, 85, 110, 105, 99, 111, 100, 101, 226, 128, 157, 32, 105, 110, 32, 111, 117, 114, 32, 115, 111, 102, 116, 119, 97, 114, 101, 32, 40, 119, 104, 97, 116, 101, 118, 101, 114, 32, 116, 104, 97, 116, 32, 109, 101, 97, 110, 115, 226, 128, 148, 108, 105, 107, 101, 32, 117, 115, 105, 110, 103, 32, 119, 99, 104, 97, 114, 95, 116, 32, 102, 111, 114, 32, 97, 108, 108, 32, 116, 104, 101, 32, 115, 116, 114, 105, 110, 103, 115, 44, 32, 114, 105, 103, 104, 116, 63, 41, 46, 32, 66, 117, 116, 32, 85, 110, 105, 99, 111, 100, 101, 32, 99, 97, 110, 32, 98, 101, 32, 97, 98, 115, 116, 114, 117, 115, 101, 44, 32, 97, 110, 100, 32, 100, 105, 118, 105, 110, 103, 32, 105, 110, 116, 111, 32, 116, 104, 101, 32, 116, 104, 111, 117, 115, 97, 110, 100, 45, 112, 97, 103, 101, 32, 85, 110, 105, 99, 111, 100, 101, 32, 83, 116, 97, 110, 100, 97, 114, 100, 32, 112, 108, 117, 115, 32, 105, 116, 115, 32, 100, 111, 122, 101, 110, 115, 32, 111, 102, 32, 115, 117, 112, 112, 108, 101, 109, 101, 110, 116, 97, 114, 121, 32, 97, 110, 110, 101, 120, 101, 115, 44, 32, 114, 101, 112, 111, 114, 116, 115, 44, 32, 97, 110, 100, 32, 110, 111, 116, 101, 115, 32, 99, 97, 110, 32, 98, 101, 32, 109, 111, 114, 101, 32, 116, 104, 97, 110, 32, 97, 32, 108, 105, 116, 116, 108, 101, 32, 105, 110, 116, 105, 109, 105, 100, 97, 116, 105, 110, 103, 46, 32, 73, 32, 100, 111, 110, 226, 128, 153, 116, 32, 98, 108, 97, 109, 101, 32, 112, 114, 111, 103, 114, 97, 109, 109, 101, 114, 115, 32, 102, 111, 114, 32, 115, 116, 105, 108, 108, 32, 102, 105, 110, 100, 105, 110, 103, 32, 116, 104, 101, 32, 119, 104, 111, 108, 101, 32, 116, 104, 105, 110, 103, 32, 109, 121, 115, 116, 101, 114, 105, 111, 117, 115, 44, 32, 101, 118, 101, 110, 32, 51, 48, 32, 121, 101, 97, 114, 115, 32, 97, 102, 116, 101, 114, 32, 85, 110, 105, 99, 111, 100, 101, 226, 128, 153, 115, 32, 105, 110, 99, 101, 112, 116, 105, 111, 110, 46]\n"
     ]
    }
   ],
   "source": [
    "tokens = list(text.encode('utf-8'))\n",
    "print(type(tokens[0]), len(tokens), tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3958b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most common pairs\n",
    "def get_stats(ids):\n",
    "  stats = {}\n",
    "  for pair in zip(ids, ids[1:]):\n",
    "    stats[pair] = stats.get(pair, 0) + 1\n",
    "  return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da470af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n",
      "(101, 32)\n"
     ]
    }
   ],
   "source": [
    "stats = get_stats(tokens)\n",
    "print(len(stats))\n",
    "top_pair = max(stats, key=stats.get)\n",
    "print(top_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f3129f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge specific pair\n",
    "def merge(ids, pair, idx):\n",
    "  newids = []\n",
    "  i = 0\n",
    "  while i < len(ids):\n",
    "    if i < len(ids) - 1 and (ids[i], ids[i+1]) == pair:\n",
    "      newids.append(idx)\n",
    "      i += 2\n",
    "    else:\n",
    "      newids.append(ids[i])\n",
    "      i += 1\n",
    "  return newids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d168da03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens2 = merge(tokens, top_pair, 256)\n",
    "len(tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8b5acbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging (101, 32) into 256\n",
      "merging (240, 159) into 257\n",
      "merging (226, 128) into 258\n",
      "merging (105, 110) into 259\n",
      "merging (115, 32) into 260\n",
      "merging (97, 110) into 261\n",
      "merging (116, 104) into 262\n",
      "merging (257, 133) into 263\n",
      "merging (257, 135) into 264\n",
      "merging (97, 114) into 265\n",
      "merging (239, 189) into 266\n",
      "merging (258, 140) into 267\n",
      "merging (267, 264) into 268\n",
      "merging (101, 114) into 269\n",
      "merging (111, 114) into 270\n",
      "merging (116, 32) into 271\n"
     ]
    }
   ],
   "source": [
    "# train tokenizer: decide on new vocab size, iterate training dataset vocab size - 256  times and do merges for most frequent pair\n",
    "vocab_size = 272\n",
    "num_iters = vocab_size - 256\n",
    "merges = {}\n",
    "ids = list(tokens)\n",
    "\n",
    "for i in range(num_iters):\n",
    "  stats = get_stats(ids)\n",
    "  pair = max(stats, key=stats.get)\n",
    "  idx = 256 + i\n",
    "  print(f'merging {pair} into {idx}')\n",
    "  ids = merge(ids, pair, idx)\n",
    "  merges[pair] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e21dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode, using vocab built from merges\n",
    "vocab = {i:bytes([i]) for i in range(256)}\n",
    "for (p1,p2), idx in merges.items():\n",
    "  vocab[idx] = vocab[p1] + vocab[p2]\n",
    "\n",
    "def decode(ids):\n",
    "  # given encoded ids, return string\n",
    "  return b''.join(vocab[i] for i in ids).decode('utf-8', errors='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d6033b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = decode(ids)\n",
    "text2 == text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72617e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'�'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b209413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "makemore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
